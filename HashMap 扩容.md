# HashMap 扩容

## 扩容前先要了解一下基本的数据结构

基本构成为 数组加链表

1. 查询时先根据hashcode找到某一位置，再根据对应位置的比较决定是否加入，相同元素的hashcode一定相同，但是不同的对象hashcode也可能相同。添加顺序如图所示

![image-20200308162417466](https://github.com/ARKbreeze/blog/blob/master/img/image-20200308162417466.png?raw=true)

2.  为了增加整体的效率，我们当然希望所有的数组位下链表长度都是均匀分布的，正常想法当然是hashcode都与数组长度进行取模，将整体哈希进行分段。

## HashMap 数组的初始容量

1. 初始容量是16，也就是2^4，为什么是这样呢，这正是为了让整体的分散更平均而进行的最优的选择，
2. 哈希分段采取“与”运算(&),当数组长度位2的次方时，数组长度-1为每位都为1的数据，进行与运算时能将所有的位置都用上，减少了碰撞次数，使得效率会更高。

## HashMap 扩容

1. 初始容量会在接近的数值采用2的次方的大小
2. 默认负载因子是0.75，在存储数据达到初始大小*负载因子时会进行扩容
3. 扩容会移动一位保持本身还是2的次方
4. jdk7 扩容会将原有的的数值全部重新计算然后放入新的map中所以比较耗费性能
5. 在1.8中采用红黑树，原本计算结果其实都是要么原本位置不变，要么移动一个数组长度的距离，在红黑树中采用一个操作可以简化这个过程（不是很清楚，有机会再进行了解）
6. 扩容举了一个例子，预设元素个数，预设值为1000，那么会分配2048的初始容量，1000接近1024，那么会是1024，又因为1024*0.75<1000,为了大于1024，采用了2048，
7. 我认为是扩容过程消耗性能尽量减少扩容发生
